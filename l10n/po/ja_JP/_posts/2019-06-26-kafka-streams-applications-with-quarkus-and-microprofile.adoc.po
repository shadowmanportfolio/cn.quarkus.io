# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-04-29 21:23+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "gmorling"
msgstr "グモルリング"

#. type: YAML Front Matter: date
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "2019-06-26"
msgstr "2019-06-26"

#. type: YAML Front Matter: layout
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "post"
msgstr "ポスト"

#. type: YAML Front Matter: tags
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "kafka microprofile"
msgstr "カフマイクロプロファイル"

#. type: YAML Front Matter: title
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:1
#, fuzzy, no-wrap
msgid "Building Kafka Streams applications with Quarkus and Eclipse MicroProfile"
msgstr ""
"layout: post\n"
"title: 「QuarkusとEclipse MicroProfileによるKafka Streamsアプリケーションの構築\n"
"date: 2019-06-26\n"
"tags: kafka microprofile\n"
"author: gmorling\n"
"---\n"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:12
#, fuzzy
msgid "https://kafka.apache.org/documentation/streams/[Kafka Streams] is a very popular solution for implementing stream processing applications based on Apache Kafka.  It lets you do typical data streaming tasks like filtering and transforming messages, joining multiple Kafka topics, performing (stateful) calculations, grouping and aggregating values in time windows and much more."
msgstr "link:https://kafka.apache.org/documentation/streams/[Kafka Streams]は、Apache Kafkaをベースにしたストリーム処理アプリケーションを実装するための、非常に人気の高いソリューションです。メッセージのフィルタリングや変換、複数のKafkaトピックの結合、（ステートフルな）計算の実行、時間軸での値のグループ化や集約など、典型的なデータストリーミングタスクを実行できます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:17
#, fuzzy
msgid "Unlike other streaming query engines that run on specific processing clusters, Kafka Streams is a client library.  This means a (Java) application is needed which starts and runs the streaming pipeline, reading from and writing to the Apache Kafka cluster."
msgstr "特定の処理クラスタ上で動作する他のストリーミングクエリエンジンとは異なり、Kafka Streamsはクライアントライブラリです。つまり、ストリーミング・パイプラインを起動・実行し、Apache Kafkaクラスターとの間で読み書きを行う（Java）アプリケーションが必要となります。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:20
#, fuzzy
msgid "In this blog post we'll discuss how the combination of Quarkus and https://microprofile.io/[Eclipse MicroProfile] is a great foundation for implementing Kafka Streams applications, running on the JVM and as native code compiled ahead of time via https://www.graalvm.org/[GraalVM]."
msgstr "このブログ記事では、Quarkusと link:https://microprofile.io/[Eclipse MicroProfile]の組み合わせが、Kafka Streamsアプリケーションを実装するための優れた基盤となり、JVM上で、また link:https://www.graalvm.org/[GraalVM]を介して事前にコンパイルされたネイティブコードとして実行されることについて説明します。"

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:21
#, fuzzy, no-wrap
msgid "The Quarkus extension for Kafka Streams"
msgstr "Kafka StreamsのためのQuarkus拡張機能"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:25
#, fuzzy
msgid "As of version 0.17.0, Quarkus comes with link:/guides/kafka-streams[an extension] for building Kafka Streams applications.  To create a new Quarkus project with this extension, run the following:"
msgstr "バージョン0.17.0の時点で、QuarkusにはKafka Streamsアプリケーションを構築するための link:/guides/kafka-streams[エクステンション]が付属しています。このエクステンションを使用して新しいQuarkusプロジェクトを作成するには、次のように実行します。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:32
#, no-wrap
msgid ""
"mvn io.quarkus:quarkus-maven-plugin:0.17.0:create \\\n"
"   -DprojectGroupId=org.acme \\\n"
"   -DprojectArtifactId=kafka-streams-quickstart-example \\\n"
"   -Dextensions=\"kafka-streams\"\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:36
#, fuzzy
msgid "This will set up a new project, adding the dependency to the Quarkus Kafka Streams extension, which in turn will pull in Kafka Streams and all its dependencies."
msgstr "これにより、新しいプロジェクトが設定され、Quarkus Kafka Streams extensionに依存関係が追加され、Kafka Streamsとそのすべての依存関係が引き込まれます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:40
#, fuzzy
msgid "If you've worked with Kafka Streams before, the implementation of a data streaming pipeline will look very familiar to you.  You first build up a `Topology` and then create a `KafkaStreams` instance.  For starting and stopping the latter, Quarkus' `StartupEvent` and `ShutdownEvent` classes come in handy."
msgstr "Kafka Streamsを使ったことがある人なら、データストリーミングパイプラインの実装はとても馴染み深いものになるでしょう。まず `Topology` を構築し、次に `KafkaStreams` のインスタンスを作成します。後者の起動と停止には、Quarkusの `StartupEvent` と `ShutdownEvent` クラスが便利です。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:42
#, fuzzy
msgid "Overall, the structure of a Kafka Streams pipeline running on Quarkus will look like so:"
msgstr "全体として、Quarkus上で動作するKafka Streamsパイプラインの構造は次のようになります。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:47
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:240
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class MyStreamingPipeline {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:49
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:182
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:245
#, no-wrap
msgid "    private KafkaStreams streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:54
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // set up Kafka Streams config, e.g. sourced from application.properties\n"
"        Properties props = new Properties();\n"
"        // props.put(..., ...);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:58
#, no-wrap
msgid ""
"        // set up the stream topology\n"
"        StreamsBuilder builder = new StreamsBuilder();\n"
"        // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:62
#, no-wrap
msgid ""
"        streams = new KafkaStreams(builder.build(), props);\n"
"        streams.start();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:67
#, no-wrap
msgid ""
"    void onStop(@Observes ShutdownEvent event) {\n"
"        streams.close();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:73
#, fuzzy
msgid "For the very common requirement that you'd like to serialize and deserialize Java types used in the streaming pipeline into/from JSON (e.g. when materializing them in a state store), the Quarkus Kafka Streams extension provides the class `io.quarkus.kafka.client.serialization.JsonbSerde`.  It's a `Serde` implementation based on JSON-B:"
msgstr "ストリーミングパイプラインで使用されるJava型をJSONとの間でシリアライズおよびデシリアライズしたいという非常に一般的な要件に対して、Quarkus Kafka Streams extensionは、 `io.quarkus.kafka.client.serialization.JsonbSerde` というクラスを提供しています。これは、JSON-Bに基づく `Serde` の実装です。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:78
#, no-wrap
msgid ""
"...\n"
"JsonbSerde<WeatherStation> weatherStationSerde = new JsonbSerde<>(WeatherStation.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:84
#, no-wrap
msgid ""
"GlobalKTable<Integer, WeatherStation> stations = builder.globalTable(\n"
"    \"weather-stations\",\n"
"    Consumed.with(Serdes.Integer(), weatherStationSerde)\n"
");\n"
"...\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:86
#, no-wrap
msgid "Running Native"
msgstr "ネイティブ実行"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:91
#, fuzzy
msgid "Based on Kafka's notion of topic partitioning, Kafka Streams applications can easily be scaled out: the load will be shared amongst multiple instances of the application, each processing just a subset of the partitions of the input topic(s)."
msgstr "Kafkaのトピックパーティショニングの概念に基づいて、Kafka Streamsアプリケーションは簡単にスケールアウトできます。負荷はアプリケーションの複数のインスタンスで共有され、それぞれが入力トピックのパーティションのサブセットだけを処理します。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:96
#, fuzzy
msgid "Running Quarkus applications in native code via GraalVM comes in very handy for that: besides the very fast start-up time, the applications will use significantly less memory when compiled to native code.  This lets you spin up many instances of a Quarkus-based Kafka Streams pipeline in parallel, in a very memory-efficient way."
msgstr "起動時間が非常に速いだけでなく、ネイティブコードにコンパイルされたアプリケーションはメモリ使用量が大幅に少なくなります。これにより、QuarkusベースのKafka Streamsパイプラインの多くのインスタンスを、非常にメモリ効率の良い方法で並行して立ち上げることができます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:101
#, fuzzy
msgid "The extension takes care of everything needed for building native Kafka Streams applications, for instance it makes sure that the right RocksDB native libraries are added to the application image.  All you need to do is to specify the `enableJni` option for the Quarkus Maven plug-in, allowing those native libraries to be invoked via JNI:"
msgstr "この拡張機能は、ネイティブなKafka Streamsアプリケーションの構築に必要なすべての作業を行います。例えば、適切なRocksDBネイティブライブラリがアプリケーションイメージに追加されていることを確認します。必要なのは、Quarkus Mavenプラグインに `enableJni` オプションを指定することで、これらのネイティブライブラリをJNI経由で呼び出すことができます。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:118
#, no-wrap
msgid ""
"<plugin>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-maven-plugin</artifactId>\n"
"    <executions>\n"
"        <execution>\n"
"            <goals>\n"
"                <goal>native-image</goal>\n"
"            </goals>\n"
"            <configuration>\n"
"                <enableJni>true</enableJni>\n"
"            </configuration>\n"
"        </execution>\n"
"    </executions>\n"
"</plugin>\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:123
#, fuzzy
msgid "When using the `JsonbSerde` for unmarshalling JSON into corresponding Java objects, those types must be marked with the `@RegisterForReflection` annotation, so that they can to be instantiated reflectively by JSON-B in native mode:"
msgstr "JSONを対応するJavaオブジェクトにアンマーシャルするために `JsonbSerde` を使用する場合、それらの型に `@RegisterForReflection` アノテーションを付ける必要があります。これにより、ネイティブモードのJSON-Bで反射的にインスタンス化することができます。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:128
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:132
#, no-wrap
msgid ""
"    public int id;\n"
"    public String name;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:136
#, fuzzy
msgid "Then build the application using the `native` profile (note this requires GraalVM to be installed on your system; refer to the Quarkus link:/guides/building-native-image[native image] guide to learn more):"
msgstr "次に、 `native` プロファイルを使用してアプリケーションを構築します（この作業には、システムにGraalVMがインストールされている必要がありますので、詳しくはQuarkus link:/guides/building-native-image[ネイティブイメージガイド]を参照してください）。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:140
#, no-wrap
msgid "mvn clean package -f aggregator/pom.xml -Pnative\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:147
#, fuzzy
msgid "Finding the right amount of memory needed for running the application can require some testing.  E.g. observe CPU load and run the native binary with the `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` options in order to gain insight into how often garbage collection kicks in.  If you started the application with not enough heap space, you'll typically observe that GC is happening very frequently, causing increased CPU load."
msgstr "アプリケーションの実行に必要な適切なメモリ量を見つけるには、いくつかのテストが必要です。例えば、ガベージコレクションがどのくらいの頻度で行われるかを知るために、CPU負荷を観察したり、ネイティブバイナリを `-XX:+PrintGC -XX:+PrintGCTimeStamps -XX:+VerboseGC` のオプションで実行したりします。十分なヒープ領域がない状態でアプリケーションを起動した場合、GCが非常に頻繁に行われ、CPU負荷が増大することがわかります。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:154
#, fuzzy
msgid "To give an example, for the https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[streaming pipeline] discussed in the Kafka Streams extension guide, a heap size of 32 MB (`-Xmx32m`) works very well, resulting in less than 50 MB memory needed by the process in total (RSS, resident set size).  Note that this number also contains the memory needed for the HTTP endpoint defined in that example, which is used for answering interactive queries via REST."
msgstr "例を挙げると、Kafka Streams extension guideで説明している link:https://github.com/quarkusio/quarkus-quickstarts/tree/main/kafka-streams-quickstart[ストリーミングパイプライン]では、ヒープサイズを32MB( `-Xmx32m`)にすると非常に効果的で、その結果、プロセスが必要とするメモリは合計で50MB以下になります（RSS、レジデントセットサイズ）。この数字には、この例で定義されているHTTPエンドポイントに必要なメモリも含まれていることに注意してください。このエンドポイントは、RESTによるインタラクティブなクエリに応答するために使用されます。"

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:155
#, fuzzy, no-wrap
msgid "Gaining Operational Insight"
msgstr "オペレーショナル・インサイトの獲得"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:161
#, fuzzy
msgid "One of the nice things about Quarkus is that it comes with support for all the Eclipse MicroProfile APIs.  They help to address common requirements when building microservices, such as https://microprofile.io/project/eclipse/microprofile-health[health checks] (\"Is my application running and ready to handle requests?\")  and https://microprofile.io/project/eclipse/microprofile-metrics[metrics] (\"What's the throughput of my application?\", \"How many requests has it processed?\" etc.)."
msgstr "Quarkusの優れた点の1つは、Eclipse MicroProfile APIのすべてがサポートされていることです。これらのAPIは、 link:https://microprofile.io/project/eclipse/microprofile-health[ヘルスチェック]（「アプリケーションが実行されていて、リクエストを処理する準備ができているか」）や link:https://microprofile.io/project/eclipse/microprofile-metrics[メトリクス]（「アプリケーションのスループットはどのくらいか」、「何件のリクエストを処理したか」など）など、マイクロサービスを構築する際の一般的な要件に対応するのに役立ちます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:165
#, fuzzy
msgid "Based on those APIs, it just requires a little bit of coding to implement health checks and metrics for a Kafka Streams application.  You can add the right dependencies by running:"
msgstr "これらのAPIをベースに、Kafka Streamsアプリケーションのヘルスチェックやメトリクスを実装するには、ほんの少しのコーディングが必要です。実行することで、正しい依存関係を追加することができます。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:169
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"health,metrics\"\n"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:171
#, fuzzy, no-wrap
msgid "Healthchecks"
msgstr "健康診断"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:174
#, fuzzy
msgid "Then creating the health check is as simple as adding the following to the pipeline implementation:"
msgstr "その後、ヘルスチェックを作成するには、パイプラインの実装に以下を追加するだけです。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:180
#, no-wrap
msgid ""
"@Liveness\n"
"@ApplicationScoped\n"
"public class MyStreamingPipeline implements HealthCheck {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:184
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:254
#, no-wrap
msgid "    // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:192
#, no-wrap
msgid ""
"    @Override\n"
"    public HealthCheckResponse call() {\n"
"        return HealthCheckResponse.named(\"My Pipeline\")\n"
"                .state(streams.state().isRunning())\n"
"                .build();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:196
#, fuzzy
msgid "This will expose a health check via HTTP under `/health/live`, which when queried will yield a response like this:"
msgstr "これにより、HTTP経由で `/health/live` のヘルスチェックが公開され、クエリを実行すると以下のようなレスポンスが得られます。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:204
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 144\n"
"Content-Type: application/json;charset=UTF-8\n"
"Date: Wed, 26 Jun 2019 10:08:36 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:214
#, no-wrap
msgid ""
"{\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"My Pipeline\",\n"
"            \"status\": \"UP\"\n"
"        }\n"
"    ],\n"
"    \"status\": \"UP\"\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:221
#, fuzzy
msgid "When using a container orchestrator such as Kubernetes, you could then set up a https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[liveness probe] for this endpoint.  If the health check fails (i.e. the streaming pipeline is not in the running state), it will return an HTTP 503 response.  This would be the indicator to the orchestrator to restart the pod of this application."
msgstr "Kubernetesなどのコンテナオーケストレーターを使用している場合は、このエンドポイントに link:https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/[livenessプローブ]を設定することができます。ヘルスチェックが失敗した場合（ストリーミングパイプラインが実行中の状態でない場合）、HTTP 503レスポンスが返されます。これが、このアプリケーションのポッドを再起動するためのオーケストレーターへの指標となる。"

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:222
#, no-wrap
msgid "Metrics"
msgstr "メトリクス"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:228
#, fuzzy
msgid "While a health check provides simple means of finding out whether the application is in a state where it can handle requests/messages or not, it is desirable to have more insight into the behaviour of the service.  E.g. it might be of interest to see how many messages have been processed by the streaming pipeline, what's the arrival rate of messages, what's the average processing time and much more."
msgstr "ヘルスチェックは、アプリケーションがリクエスト/メッセージを処理できる状態にあるかどうかを知るための簡単な手段を提供しますが、サービスの動作についてより多くの情報を得ることが望まれます。例えば、ストリーミング・パイプラインによって処理されたメッセージの数、メッセージの到着率、平均処理時間などを確認することは興味深いことでしょう。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:233
#, fuzzy
msgid "Kafka Streams comes with https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[rich metrics] capabilities which can help to answer these questions.  Using the MicroProfile Metrics API, these metrics can be exposed via HTTP.  From there they can be scraped by tools such as https://prometheus.io/[Prometheus] and eventually be fed to dashboard solutions such as https://grafana.com/[Grafana].  Note that exposing metrics via HTTP instead of JMX has the advantage that this also works when running the application in native mode via GraalVM."
msgstr "Kafka Streamsには link:https://kafka.apache.org/22/javadoc/org/apache/kafka/streams/KafkaStreams.html#metrics--[豊富なメトリクス]機能があり、これらの疑問に答えることができます。MicroProfile Metrics APIを使えば、これらのメトリクスをHTTPで公開することができます。そこから link:https://prometheus.io/[Prometheus]などのツールでスクレイピングし、最終的には link:https://grafana.com/[Grafana]などのダッシュボードソリューションに供給することができます。なお、JMXではなくHTTPでメトリクスを公開することで、GraalVMを介してネイティブモードでアプリケーションを実行する際にも動作するという利点があります。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:235
#, fuzzy
msgid "Similar to the health check case, just a bit of glue code is needed for exposing the metrics:"
msgstr "ヘルスチェックの場合と同様に、メトリクスを公開するためには、ほんの少しのグルーコードが必要です。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:243
#, no-wrap
msgid ""
"    @Inject\n"
"    MetricRegistry metricRegistry;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:248
#, no-wrap
msgid ""
"    void onStart(@Observes StartupEvent event) {\n"
"        // ...\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:252
#, no-wrap
msgid ""
"        streams.start();\n"
"        exportMetrics();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:257
#, no-wrap
msgid ""
"    private void exportMetrics() {\n"
"        Set<String> processed = new HashSet<>();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:261
#, no-wrap
msgid ""
"        for (Metric metric : streams.metrics().values()) {                // <1>\n"
"            String name = metric.metricName().group() +\n"
"                    \":\" + metric.metricName().name();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:265
#, no-wrap
msgid ""
"            if (processed.contains(name)) {\n"
"                continue;\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:277
#, no-wrap
msgid ""
"            // string-typed metric not supported\n"
"            if (name.contentEquals(\"app-info:commit-id\") ||               // <2>\n"
"                    name.contentEquals(\"app-info:version\")) {\n"
"                continue;\n"
"            }\n"
"            else if (name.endsWith(\"count\") || name.endsWith(\"total\")) {  // <3>\n"
"                registerCounter(metric, name);\n"
"            }\n"
"            else {\n"
"                registerGauge(metric, name);                              // <4>\n"
"            }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:281
#, no-wrap
msgid ""
"            processed.add(name);\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:285
#, no-wrap
msgid ""
"    private void registerGauge(Metric metric, String name) {\n"
"        Metadata metadata = new Metadata(name, MetricType.GAUGE);\n"
"        metadata.setDescription(metric.metricName().description());\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:287
#, no-wrap
msgid "        metricRegistry.register(metadata, new Gauge<Double>() {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:294
#, no-wrap
msgid ""
"            @Override\n"
"            public Double getValue() {\n"
"                return (Double) metric.metricValue();\n"
"            }\n"
"        } );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:299
#, no-wrap
msgid ""
"    private void registerCounter(Metric metric, String name) {\n"
"        // ...\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:301
#, fuzzy
msgid "Process all Kafka Streams metrics, using a unique name to register them"
msgstr "すべてのKafka Streamsのメトリクスを処理し、一意の名前を使って登録する"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:302
#, fuzzy
msgid "Some string-typed \"metrics\" must be excluded"
msgstr "文字列型の \"メトリクス \"は除外する必要があります。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:303
#, fuzzy
msgid "All metrics whose name ends with \"total\" or \"counter\" will be exposed as counter-typed metrics"
msgstr "名前が \"total \"または \"counter \"で終わるすべてのメトリクスは、カウンター型のメトリクスとして公開されます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:304
#, fuzzy
msgid "All other metrics will be exposed as gauge-typed metrics, i.e. plain numeric values"
msgstr "他のすべてのメトリクスは、ゲージタイプのメトリクス、つまり単純な数値として公開されます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:307
#, fuzzy
msgid "Once the application is started, the metrics will be exposed under `/metrics`, returning the data in the OpenMetrics format by default:"
msgstr "アプリケーションが起動すると、メトリクスは `/metrics` で公開され、デフォルトで OpenMetrics フォーマットのデータが返されます。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:317
#, no-wrap
msgid ""
"# HELP application:stream_metrics_process_total The total number of occurrence of process operations.\n"
"# TYPE application:stream_metrics_process_total counter\n"
"application:stream_metrics_process_total 2866.0\n"
"# HELP application:stream_metrics_poll_latency_avg The average latency of poll operation.\n"
"# TYPE application:stream_metrics_poll_latency_avg gauge\n"
"application:stream_metrics_poll_latency_avg 83.3135593220339\n"
"# ...\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:323
#, fuzzy
msgid "From here it's a matter of minutes to set up Prometheus to scrape this target, configure a Prometheus data source in Grafana and configure a dashboard for visualizing the metrics of interest to you.  E.g. the following shows a simple dashboard displaying the poll/process/commit rates and latencies as well as the total number of processed events in the quickstart example:"
msgstr "ここからは、Prometheus を設定してこのターゲットをスクレイプし、Grafana で Prometheus のデータソースを設定し、関心のあるメトリクスを可視化するためのダッシュボードを設定するのに数分かかります。例えば、以下はクイックスタートの例で、ポーリング/プロセス/コミットのレートとレイテンシー、および処理されたイベントの総数を表示するシンプルなダッシュボードを示しています。"

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, fuzzy, no-wrap
msgid "Kafka Streams metrics in Grafana"
msgstr "GrafanaにおけるKafka Streamsのメトリクス"

#. type: Target for macro image
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:324
#, no-wrap
msgid "/assets/images/kafka-streams-metrics.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:326
#, fuzzy, no-wrap
msgid "Summary and Outlook"
msgstr "概要と展望"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:332
#, fuzzy
msgid "Quarkus and Eclipse MicroProfile are a great basis for building Kafka Streams applications.  The Quarkus extension for Kafka Streams comes with everything needed to run stream processing pipelines on the JVM as well as in native mode via GraalVM.  The MicroProfile APIs for health checks and metrics can be used to expose the right information for gaining insight into running stream processing applications."
msgstr "QuarkusとEclipse MicroProfileは、Kafka Streamsアプリケーションを構築するための優れた基盤となります。Kafka Streams用のQuarkus拡張機能には、ストリーム処理パイプラインをJVM上で実行するだけでなく、GraalVMを介してネイティブモードで実行するために必要なものがすべて付属しています。ヘルスチェックとメトリクスのためのMicroProfile APIを使用して、実行中のストリーム処理アプリケーションの洞察を得るための適切な情報を公開することができます。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:336
#, fuzzy
msgid "Going forward, we plan to further reduce the efforts needed for building Kafka Streams applications on Quarkus.  Instead of having to deal with the lifecycle of the pipeline yourself, it should be enough to declare a CDI producer method returning the streaming `Topology`:"
msgstr "今後は、Quarkus上でKafka Streamsアプリケーションを構築するために必要な労力をさらに軽減する予定です。パイプラインのライフサイクルを自分で処理するのではなく、ストリーミング `Topology` を返すCDIプロデューサーメソッドを宣言するだけで十分でしょう。"

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:344
#, no-wrap
msgid ""
"@Produces\n"
"public Topology buildTopology()  {\n"
"    // set up the stream topology\n"
"    StreamsBuilder builder = new StreamsBuilder();\n"
"    // builder.stream(...)\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:347
#, no-wrap
msgid ""
"    return builder.build();\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:353
#, fuzzy
msgid "This means you'll be able to focus on implementing the actual pipeline logic, while the Quarkus extension would take care of everything else: configuring Kafka Streams based on the Quarkus `application.properties` file, starting the pipeline and automatically exposing healthchecks and metrics."
msgstr "つまり、実際のパイプラインロジックの実装に集中することができます。Quarkusエクステンションは、Quarkus `application.properties` ファイルに基づいてKafka Streamsを設定し、パイプラインを開始し、ヘルスチェックやメトリクスを自動的に公開するなど、その他のすべての作業を行います。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:357
#, fuzzy
msgid "In case this sounds interesting to you, have an eye on the next Quarkus release announcements, as this improved functionality should be out soon.  If you got any related ideas, let us know and join the discussion in Quarkus issue https://github.com/quarkusio/quarkus/issues/2863[#2863]."
msgstr "この改善された機能はすぐにリリースされるはずですので、次回のQuarkusリリースのアナウンスに注目してください。また、関連するアイデアがありましたら、Quarkus issue link:https://github.com/quarkusio/quarkus/issues/2863[#2863]で議論に参加してください。"

#. type: Plain text
#: upstream/_posts/2019-06-26-kafka-streams-applications-with-quarkus-and-microprofile.adoc:361
#, fuzzy
msgid "To learn more about the Quarkus extension for Kafka Streams and its current capabilities, check out link:/guides/kafka-streams[the detailed guide].  It not only discusses the actual stream pipeline implementation, but also touches on building (distributed) interactive queries for exposing the current processing state via REST."
msgstr "Kafka Streams用のQuarkus拡張機能とその現在の機能については、 link:/guides/kafka-streams[詳細なガイド]をご覧ください。実際のストリームパイプラインの実装についてだけでなく、現在の処理状況をREST経由で公開するための（分散）インタラクティブなクエリの構築についても触れています。"

#, fuzzy
#~ msgid "---\n"
#~ msgstr "---\n"
