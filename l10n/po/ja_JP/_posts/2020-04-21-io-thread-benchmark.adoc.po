# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-04-29 21:23+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "ebernard"
msgstr "エベナール"

#. type: YAML Front Matter: date
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "2020-04-21"
msgstr "2020-04-21"

#. type: YAML Front Matter: layout
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "post"
msgstr "ポスト"

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "Understand when and how to use the Quarkus IO thread and its influence on microbenchmarks."
msgstr "Quarkus IOスレッドの使用タイミングと使用方法、およびマイクロベンチマークへの影響について理解しています。"

#. type: YAML Front Matter: tags
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "performance"
msgstr "パフォーマンス"

#. type: YAML Front Matter: title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:1
#, fuzzy, no-wrap
msgid "A IO thread and a worker thread walk into a bar: a microbenchmark story"
msgstr "IOスレッドとワーカスレッドがバーに入る: マイクロベンチマークの話"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:17
#, fuzzy
msgid "A competitor recently published a microbenchmark comparing the performance of their stack to Quarkus.  The Quarkus team feels this microbenchmark shouldn’t be taken at face value because it wasn’t making a like-to-like comparison leading to incorrect conclusions.  Both of the two frameworks under comparison support reactive processing.  Reactive processing enables running the business logic directly on the _IO thread_, which ultimately performs better in microbenchmark focusing on response time and concurrency.  The microbenchmark should have been written so that both frameworks (or neither framework) obtain this benefit.  Anyway, this turns out to be a very interesting topic and good information for Quarkus users, so read on."
msgstr "競合他社が最近、自社のスタックとQuarkusのパフォーマンスを比較したマイクロベンチマークを公開しました。Quarkusチームは、このマイクロベンチマークを額面通りに受け取るべきではないと考えています。理由は、同種の比較を行っていないため、誤った結論になるからです。比較対象となった2つのフレームワークは、どちらもリアクティブ処理をサポートしています。リアクティブ処理では、ビジネスロジックを _IOスレッド_上で直接実行することができ、応答時間と並行性に焦点を当てたマイクロベンチマークでは、最終的に優れたパフォーマンスを発揮します。マイクロベンチマークは、両方のフレームワーク（あるいはどちらのフレームワークでもないもの）がこのメリットを得られるように書かれているべきでした。いずれにしても、これは非常に興味深いトピックであり、Quarkusのユーザーにとっても良い情報となりますので、ぜひお読みください。"

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:18
#, fuzzy, no-wrap
msgid "tl; dr;"
msgstr "tl;dr。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:22
#, fuzzy
msgid "Quarkus https://quarkus.io/blog/runtime-performance/[has great performance] for both imperative and reactive workloads.  It’s because Quarkus is itself based on Eclipse Vert.x, a mature top performing reactive framework, in such a way that allows you to layer, mix and match the IO paradigm that best fits your use-case."
msgstr "Quarkus link:https://quarkus.io/blog/runtime-performance/[は]、インペラティブなワークロードとリアクティブなワークロードの両方で link:https://quarkus.io/blog/runtime-performance/[優れたパフォーマンス]を発揮します。これは、Quarkus自体が、成熟した最高性能のリアクティブフレームワークであるEclipse Vert.xをベースにしているためであり、ユースケースに最も適したIOパラダイムを重ねたり、組み合わせたりすることができます。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:24
#, fuzzy
msgid "If you have a REST scenario well suited to run _purely on the IO thread_, add a Vert.x Reactive Route using https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] and your app will get better performance than using Quarkus RESTEasy."
msgstr "_純粋にIOスレッドで_実行するのに適したRESTシナリオがある場合、 link:https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes]を使用してVert.x Reactive Routeを追加すると、アプリはQuarkus RESTEasyを使用するよりもパフォーマンスが向上します。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:28
#, fuzzy
msgid "We ran this low-work REST + validation competitor-written microbenchmark which features no blocking operation, just returning static data.  When using Quarkus Reactive Routes to run Quarkus _purely on the IO thread_, **we observed 2.6x times the requests/sec and 30% less memory usage (RSS)** than running with Quarkus RESTEasy (which mixes IO thread and worker thread).  But that’s on a microbenchmark purpose built to this specific scenario (more on that later)."
msgstr "ブロッキング操作を行わず、静的なデータを返すだけの、作業量の少ないREST＋検証用の競合他社が作成したマイクロベンチマークを実行しました。Quarkus Reactive Routesを使用して _純粋にIOスレッドで_Quarkusを実行した場合、Quarkus RESTEasy（IOスレッドとワーカースレッドを混在させる）で実行した場合と比較して、 *リクエスト数は2.6倍/秒、メモリ使用量は30%減少しました（RSS）*。ただし、これはこの特定のシナリオのために作られたマイクロベンチマークでの結果です（詳細は後述）。"

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:29
#, no-wrap
msgid "throughput.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:31
#, fuzzy, no-wrap
msgid "More interesting read"
msgstr "より興味深い記事"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:35
#, fuzzy
msgid "The microbenchmark itself is uninteresting, but it is a good demonstrator of a phenomenon that can happen in reactive stacks.  Let’s use it as a vehicle to learn more about Quarkus and its reactive engine."
msgstr "このマイクロベンチマーク自体は面白くありませんが、リアクティブスタックで起こりうる現象の良いデモンストレーションになっています。このマイクロベンチマークを利用して、Quarkusとそのリアクティブエンジンについて詳しく学んでみましょう。"

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:36
#, no-wrap
msgid "Imperative and Reactive: the elevator pitch"
msgstr "命令型とリアクティブ型: エレベーターピッチ"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:40
#, fuzzy
msgid "This blog post does not explain the fundamental differences between the imperative execution model and the reactive execution model.  However, to understand why we see so much difference in the mentioned microbenchmark, we need some notions."
msgstr "このブログ記事では、命令型実行モデルと反応型実行モデルの根本的な違いについては説明していません。しかし、前述のマイクロベンチマークでなぜこれほどの違いが見られるのかを理解するためには、いくつかの概念が必要です。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:49
#, fuzzy
msgid "In general, Java web applications use imperative programming combined with blocking IO operations.  This is incredibly popular because it is easier to reason about the code.  _Things_ get executed sequentially.  To make sure one request is not affected by another, they are run on different threads.  When your workload needs to interact with a database or another remote service, it relies on blocking IO.  The thread is blocked waiting for the answer.  Other requests running on different threads are not slowed down significantly.  But this means one thread for every concurrent request, which limits the overall concurrency."
msgstr "一般的に、Javaウェブアプリケーションでは、命令型のプログラミングとブロック型のIO操作が組み合わされています。これは、コードを推論するのが簡単なので、非常に人気があります。 _物事_は順番に実行されます。1つのリクエストが他のリクエストに影響されないようにするために、それらは異なるスレッドで実行されます。ワークロードがデータベースや他のリモートサービスと対話する必要がある場合、ブロッキングIOに依存します。スレッドはアンサーを待つためにブロックされます。別のスレッドで実行されている他のリクエストは、大きく減速することはありません。しかし、これでは同時実行のリクエストごとに1つのスレッドが必要となり、全体の同時実行性が制限されてしまいます。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:64
#, fuzzy
msgid "On the other side, the reactive execution model embraces asynchronous development models and non blocking IOs.  With this model, multiple requests can be handled by the same thread.  When the processing of a request cannot make progress anymore (because it requests a remote service, or interacts with a database), it uses non blocking IO.  This releases the thread immediately, which can then be used to serve another request.  When the result of the IO operation is available, the processing of the request is restored and continues its execution.  This model enables the usage of the _IO thread_ to handle multiple requests.  There are two significant benefits.  First, the response time is smaller because it does not have to jump to another thread.  Second, it reduces memory consumption as it decreases the usage of threads.  The reactive model uses the hardware resources more efficiently, but... there is a significant drawback.  If the processing of a request starts to block, this gets real bad.  No other request can be handled.  To avoid this, you need to learn how to write non blocking code, how to structure asynchronous processing, and how to use non blocking IOs.  It's a paradigm shift."
msgstr "一方、リアクティブな実行モデルは、非同期開発モデルと非ブロッキングIOを採用しています。このモデルでは、複数のリクエストを同じスレッドで処理することができます。リクエストの処理が進まなくなったとき（リモートサービスへのリクエストやデータベースとのやりとりなど）には、ノンブロッキングIOを使用します。これによりスレッドは直ちに解放され，別のリクエストに対応できるようになります．IO操作の結果が利用可能になると、リクエストの処理が復元され、実行が継続されます。このモデルでは、 _IOスレッド_を使って複数のリクエストを処理することができます。これには2つの大きなメリットがあります。まず、別のスレッドにジャンプする必要がないため、応答時間が小さくなります。2つ目は、スレッドの使用量が減るため、メモリ消費量が減ることです。リアクティブモデルは、ハードウェアリソースをより効率的に使用しますが、...重大な欠点があります。あるリクエストの処理がブロックされ始めると、これは本当にひどいことになります。他のリクエストを処理できなくなってしまうのです。これを避けるためには、ブロックしないコードの書き方、非同期処理の仕組み、ブロックしないIOの使い方などを学ぶ必要があります。これはパラダイムシフトです。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:68
#, fuzzy
msgid "In Quarkus, we want to make the shift as easy as possible.  However, we have observed that the majority of user applications are written using the imperative model.  That is why, when the user application uses JAX-RS, Quarkus defaults to execute the (imperative) workload to a _worker thread_."
msgstr "Quarkusでは、この移行をできるだけ簡単にしたいと考えています。しかし、ユーザーアプリケーションの大部分が命令型モデルを使用して書かれていることを確認しています。そのため、ユーザーアプリケーションがJAX-RSを使用している場合、Quarkusはデフォルトで（命令型の）ワークロードを _ワーカースレッド_に実行します。"

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:69
#, fuzzy, no-wrap
msgid "Hello world microbenchmark: IO thread or worker thread?"
msgstr "Hello world マイクロベンチマーク。IOスレッドかワーカースレッドか？"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:74
#, fuzzy
msgid "Back to the competitor’s microbenchmark, we have a REST endpoint doing some trivial processing and some equally trivial validation.  Pretty much no meaningful business work.  This is the Hello World of REST for all intents and purposes."
msgstr "競合他社のマイクロベンチマークに話を戻すと、RESTエンドポイントが些細な処理と同様に些細な検証を行っています。意味のあるビジネスワークはほとんどありません。これは、どこから見てもRESTのHello Worldです。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:79
#, fuzzy
msgid "When you run the microbenchmark with Quarkus RESTEasy, the request is handled by the reactive engine on the _IO thread_ but then the processing work is handed over to a second thread from the _worker thread pool_.  That’s called _dispatch_.  When your microbenchmark does as little as Hello World, then the dispatch overhead is proportionally big.  The dispatch overhead is not visible in most (real life) applications but is very visible in artificial constructs like microbenchmarks."
msgstr "Quarkus RESTEasyでマイクロベンチマークを実行すると、リクエストは _IOスレッド_でリアクティブエンジンによって処理されますが、その後、処理作業は _ワーカースレッドプール_から2番目のスレッドに引き渡されます。これを _ディスパッチ_と呼びます。マイクロベンチマークがHello Worldのような小さな処理を行う場合、ディスパッチのオーバーヘッドは比例して大きくなります。ディスパッチのオーバーヘッドは、ほとんどの（実生活の）アプリケーションでは見えませんが、マイクロベンチマークのような人工的な構造では非常によく見えます。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:83
#, fuzzy
msgid "The competitor’s stack, however, runs all the request operations on the IO thread by default.  So what this microbenchmark was actually comparing is just the cost of dispatching to the worker thread pool.  And frankly (according to the competitor's numbers) and in spite of this extra dispatch work, Quarkus did very very well achieving ~95% of the competitor’s throughput today! I say today because we are always improving upon performance, and in fact we expect to see further gains in the soon to be released 1.4 release."
msgstr "しかし、競合他社のスタックでは、デフォルトですべてのリクエスト操作をIOスレッドで実行しています。つまり、このマイクロベンチマークが実際に比較していたのは、ワーカスレッドプールへのディスパッチのコストだけなのです。率直に言って（競合他社の数字によると）、この余分なディスパッチ作業にもかかわらず、Quarkusは今日、競合他社の95％のスループットを達成し、非常に好調でした。今日と言ったのは、我々は常にパフォーマンスを向上させており、実際、間もなくリリースされる1.4ではさらなる向上が期待されているからです。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:85
#, fuzzy, no-wrap
msgid "*When compared at a disadvantage (dispatching to a worker thread), Quarkus is nevertheless almost as fast in throughput.*\n"
msgstr "*不利な条件（ワーカースレッドへのディスパッチ）で比較しても、Quarkusのスループットはほぼ同等の速さです。*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:90
#, fuzzy
msgid "… But wait, Quarkus can also avoid the dispatch altogether and run operations on the IO Thread.  This is a more accurate comparison to how the competitor' stack was configured to do as in both case, it is the user's responsibility to ask for a dispatch if and when needed by the application.  To compare apples to apples, let’s use https://quarkus.io/guides/reactive-routes[Quarkus Reactive Routes] backed by Eclipse Vert.x.  In this model, operations are run on the IO thread by default."
msgstr "...しかし、Quarkusはディスパッチを完全に回避し、IOスレッドで処理を実行することもできます。これは、競合他社のスタックがどのように構成されているかをより正確に比較しています。どちらのケースでも、アプリケーションが必要とするときにディスパッチを要求するのはユーザーの責任です。このモデルでは、操作はデフォルトでIOスレッドで実行されます。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:95
#, fuzzy
msgid "@ApplicationScoped public class MyDeclarativeRoutes {"
msgstr "@ApplicationScoped public class MyDeclarativeRoutes {..."

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:98
#, fuzzy, no-wrap
msgid ""
"  @Inject\n"
"  Validator validator;\n"
msgstr ""
"<pre>@Inject\n"
"Validator バリデータ。</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:111
#, fuzzy, no-wrap
msgid ""
"  @Route(path = \"/hello/:name\", methods = HttpMethod.GET)\n"
"  void greetings(RoutingExchange ex) {\n"
"    RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"name\").orElse(\"world\"));\n"
"    Set<ConstraintViolation<RequestWrapper>> violations = validator.validate(requestWrapper));\n"
"    if( violations.size() == 0) {\n"
"      ex.ok(\"hello \" + requestWrapper.name);\n"
"    } else {\n"
"      StringBuilder validationError = new StringBuilder();\n"
"      violations.stream().forEach(violation -> validationError.append(violation.getMessage()));\n"
"      ex.response().setStatusCode(400).end(validationError.toString());\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>@Route(path = \"/hello/:name\", methods = HttpMethod.GET)\n"
"void greetings(RoutingExchange ex) {.\n"
"  RequestWrapper requestWrapper = new RequestWrapper(ex.getParam(\"name\").orElse(\"world\"));\n"
"  Set<ConstraintViolation<RequestWrapper>> violations = validator.validate(requestWrapper));\n"
"  if( violations.size() == 0) {。\n"
"    ex.ok(\"hello \" + requestWrapper.name);\n"
"  } else {\n"
"    StringBuilder validationError = new StringBuilder();\n"
"    violations.stream().forEach(violation -> validationError.append(violation.getMessage()));\n"
"    ex.response().setStatusCode(400).end(validationError.toString());\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:115
#, fuzzy, no-wrap
msgid ""
"  private class RequestWrapper {\n"
"    @NotBlank\n"
"    public String name;\n"
msgstr ""
"<pre>private class RequestWrapper {.\n"
"  @NotBlank\n"
"  public String name;</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:120
#, fuzzy, no-wrap
msgid ""
"    public RequestWrapper(String name) {\n"
"      this.name = name;\n"
"    }\n"
"  }\n"
msgstr ""
"<pre>  public RequestWrapper(String name) {\n"
"    this.name = name;\n"
"  }\n"
"}</pre>"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:122
#, fuzzy
msgid "}"
msgstr "}"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:125
#, fuzzy
msgid "This is not very different from your JAX-RS equivalent."
msgstr "これは、JAX-RSに相当するものとあまり変わりません。"

#. type: Title ===
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:126
#, fuzzy, no-wrap
msgid "Throughput Numbers"
msgstr "スループットの数値"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:129
#, fuzzy
msgid "We ran the microbenchmark application in a docker container constrained to reflect a typical resource allocation to a container orchestrated by Kubernetes:"
msgstr "マイクロベンチマークアプリケーションは、Kubernetesでオーケストレーションされたコンテナへの典型的なリソース割り当てを反映するように制約されたdockerコンテナで実行されました。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:131
#, fuzzy
msgid "4 CPU"
msgstr "4 CPU"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:132
#, fuzzy
msgid "256 MB of RAM"
msgstr "256 MBのRAM"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:133
#, fuzzy
msgid "and `-Xmx128m` heap usage for the Java process"
msgstr "と `-Xmx128m` Javaプロセスのヒープ使用量"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:139
#, fuzzy
msgid "We saw that Quarkus using Reactive Routes ran 2.6 times the requests/sec.  2.6 times! It makes sense! Remember the application code virtually does nothing, so the dispatch cost is comparatively high.  If you were to write a more real life workload (maybe even having a blocking operation like a JPA access and therefore forcing a dispatch), then the results would be very different.  Context matters!"
msgstr "Reactive Routesを使用したQuarkusは、2.6倍のリクエスト/秒を実行することがわかりました。2.6倍！？これは理にかなっています。アプリケーションコードは実質的に何もしていないので、ディスパッチコストが比較的に高いことを覚えておいてください。もし、もっと現実的なワークロードを書いたとしたら（JPAアクセスのようなブロッキング操作があってディスパッチを余儀なくされているかもしれません）、結果は大きく変わってくるでしょう。コンテキストは重要です。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:141
#, fuzzy
msgid "You can find code and how to reproduce the microbenchmark https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[here on GitHub]."
msgstr "このマイクロベンチマークのコードと再現方法は、 link:https://github.com/johnaohara/quarkus-iothread-workerpool/tree/1.3.1.Final[GitHubのこちらの]ページでご覧いただけます。"

#. type: Block title
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:142
#, fuzzy, no-wrap
msgid "Microbenchmark results comparing Quarkus dispatching to a worker thread vs running purely on the IO thread"
msgstr "Quarkusがワーカースレッドにディスパッチした場合と、純粋にIOスレッドで実行した場合を比較したマイクロベンチマークの結果"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:146
#, fuzzy, no-wrap
msgid "Quarkus - 1.3.1.Final - 4 CPU's"
msgstr "Quarkus - 1.3.1.Final - 4 CPUs"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:147
#, no-wrap
msgid "Worker thread"
msgstr "ワーカースレッド"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:148
#, fuzzy, no-wrap
msgid "IO thread"
msgstr "IOスレッド"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:150
#, fuzzy, no-wrap
msgid "Ratio"
msgstr "比率"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:151
#, fuzzy, no-wrap
msgid "Mean Start Time to First Request (ms) footnote:[‘Mean Start Time to First Request’ was measured using an application built as an UberJar]"
msgstr "最初のリクエストまでの平均開始時間（ms）<sup class=\"footnote\">[ link:#_footnotedef_1[1, id=_footnoteref_1, role=footnote, title=View footnote.]</sup>] [2"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:152
#, fuzzy, no-wrap
msgid "993.9"
msgstr "993.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:153
#, fuzzy, no-wrap
msgid "868.3"
msgstr "868.3"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:155
#, fuzzy, no-wrap
msgid "87.4%"
msgstr "87.4%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:156
#, fuzzy, no-wrap
msgid "Max RSS (MB)"
msgstr "最大RSS (MB)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:157
#, fuzzy, no-wrap
msgid "138.8"
msgstr "138.8"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:158
#, fuzzy, no-wrap
msgid "97.9"
msgstr "97.9"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:160
#, fuzzy, no-wrap
msgid "70.5%"
msgstr "70.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:161
#, fuzzy, no-wrap
msgid "Max Throughput (req/sec)"
msgstr "最大スループット(req/sec)"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:162
#, fuzzy, no-wrap
msgid "46,172.2"
msgstr "46,172.2"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:163
#, fuzzy, no-wrap
msgid "123,520.4"
msgstr "123,520.4"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:165
#, fuzzy, no-wrap
msgid "267.5%"
msgstr "267.5%"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:166
#, fuzzy, no-wrap
msgid "Max Req/Sec/MB"
msgstr "Max Req/Sec/MB"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:167
#, fuzzy, no-wrap
msgid "332.7"
msgstr "332.7"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:168
#, fuzzy, no-wrap
msgid "1,262.1"
msgstr "1,262.1"

#. type: Table
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:169
#, fuzzy, no-wrap
msgid "379.4%"
msgstr "379.4%"

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:171
#, no-wrap
msgid "throughput-percentile.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:174
#, fuzzy, no-wrap
msgid "*In a fair comparison (purely remaining on the IO thread - no dispatch), Quarkus more than double its throughput.*\n"
msgstr "*公平な比較（純粋にIOスレッドに留まり、ディスパッチを行わない）では、Quarkusは2倍以上のスループットを実現しています。*"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:179
#, fuzzy
msgid "As the generated load tends towards the maximum throughput of the system under test, the response time experienced by the client increases exponentially.  So the best system (for the workload) has a vertical line as far to the right as possible.  Equally important is to have as flat a line as possible for the longest time.  You do not want the response time to degrade before the system reaches maximum throughput."
msgstr "生成された負荷がテスト対象のシステムの最大スループットに向かって傾くと、クライアントが経験する応答時間は指数関数的に増加します。そのため、（作業負荷に対して）最良のシステムは、垂直線が可能な限り右に寄っています。同様に重要なのは、できるだけ長い時間、平らな線を描くことです。システムが最大のスループットに達する前に、応答時間が低下することは避けたい。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:184
#, fuzzy
msgid "By the way, in the competitor microbenchmark Quarkus is shown as consuming more RSS (more RAM).This is also explained by the worker thread pool being operated whereas the competitor did not have a worker thread pool.  The Quarkus Reactive Routes solution (on a pure IO event run) shows a 30% RSS usage reduction."
msgstr "ところで、競合他社のマイクロベンチマークでは、Quarkusがより多くのRSS（より多くのRAM）を消費していることが示されています。これは、競合他社がワーカスレッドプールを持っていなかったのに対し、Quarkusはワーカスレッドプールを運用していたことからも説明できます。QuarkusのReactive Routesソリューション（純粋なIOイベントの実行時）では、RSSの使用量が30%削減されています。"

#. type: Target for macro image
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:185
#, no-wrap
msgid "rss.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:189
#, fuzzy
msgid "In this graph, the lower, the better.  We see that the pure IO thread solution manages to increase throughput with little to no change to the memory usage (RSS), that's very good!"
msgstr "このグラフでは、低ければ低いほど良いとされています。純粋なIOスレッドソリューションは、メモリ使用量（RSS）にほとんど変化を与えずに、スループットを向上させることができていることがわかります。これは非常に良いことです。"

#. type: Title ==
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:190
#, no-wrap
msgid "Conclusion"
msgstr "まとめ"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:196
#, fuzzy
msgid "Quarkus offers you the ability to safely run blocking operations, run non blocking operations on the IO thread or mix both models.  The Quarkus team takes performance very seriously and we see Quarkus as offering great numbers whether you use the imperative or reactive models.  In more realistic workloads, the dispatch cost would be much less significant, you would not see such drastic differences between the two approaches.  As usual, test as close to your real application as possible."
msgstr "Quarkusでは、ブロッキング処理を安全に実行したり、IOスレッドで非ブロッキング処理を実行したり、両方のモデルを混在させることができます。Quarkusチームはパフォーマンスを非常に重要視しており、命令型モデルと反応型モデルのどちらを使用しても、Quarkusは素晴らしい数値を提供すると考えています。より現実的なワークロードでは、ディスパッチのコストはそれほど重要ではなく、2つのアプローチの間にこれほど劇的な違いはないでしょう。いつものように、できるだけ実際のアプリケーションに近い状態でテストしてください。"

#. type: Plain text
#: upstream/_posts/2020-04-21-io-thread-benchmark.adoc:203
#, fuzzy
msgid "Mystery solved.  Benchmarks are hard, challenge them.  But the moral of the story is that in all bad comes some good.  We’ve now learned how to run Quarkus applications entirely on the IO thread.  And how in some situations that can make a big difference.  Remember, don’t block! In fact, Quarkus https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[can warn you if you do so].  Oh and we also learned that Quarkus is so fast, it can even beat itself ;p"
msgstr "謎が解けました。ベンチマークは難しい、チャレンジしてみてください。しかし、この話の教訓は、悪いことの中にも良いことがあるということです。今、私たちはQuarkusアプリケーションを完全にIOスレッドで実行する方法を学びました。そして、いくつかの状況ではそれが大きな違いを生むこともあります。覚えておいてほしいのは、ブロックしないことです。実際、ブロック link:https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[すると]Quarkus link:https://quarkus.io/guides/all-config#quarkus-vertx-core_quarkus.vertx.warning-exception-time[が警告して]くれます。また、Quarkusは非常に高速で、自分自身を打ち負かすこともできるということもわかりました;p"

#, fuzzy
#~ msgid "---\n"
#~ msgstr "---\n"

#, fuzzy
#~ msgid ""
#~ "layout: post\n"
#~ "title: 'A IO thread and a worker thread walk into a bar: a microbenchmark story'\n"
#~ "date: 2020-04-21\n"
#~ "tags: performance\n"
#~ "synopsis: Understand when and how to use the Quarkus IO thread and its influence on microbenchmarks.\n"
#~ "author: ebernard\n"
#~ "---\n"
#~ msgstr ""
#~ "layout: post\n"
#~ "title: 'A IO thread and a worker thread walk into a bar: a microbenchmark story'\n"
#~ "date: 2020-04-21\n"
#~ "tags: performance\n"
#~ "synopsis: QuarkusのIOスレッドをいつ、どのように使用するか、またマイクロベンチマークへの影響を理解する。\n"
#~ "author: ebernard\n"
#~ "---\n"
