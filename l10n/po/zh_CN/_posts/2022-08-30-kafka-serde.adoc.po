# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2022-08-29 06:51+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "cescoffier"
msgstr "鹤壁市"

#. type: YAML Front Matter: date
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "2022-08-30"
msgstr "2022-08-30"

#. type: YAML Front Matter: layout
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "post"
msgstr "职位"

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "JSON, Avro and Custom Kafka Serializers and Deserializers with Quarkus"
msgstr "使用Quarkus的JSON、Avro和自定义Kafka序列化器和反序列化器"

#. type: YAML Front Matter: tags
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "kafka"
msgstr "卡夫卡"

#. type: YAML Front Matter: title
#: upstream/_posts/2022-08-30-kafka-serde.adoc:1
#, fuzzy, no-wrap
msgid "How to implement Kafka Serializers and Deserializers?"
msgstr "如何实现Kafka序列化器和反序列化器？"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:14
#, fuzzy
msgid "When your application writes a _record_ into a Kafka topic or when it consumes a _record_ from a Kafka topic, a mechanism of serialization and deserialization happens.  The serialization process transforms the business objects you want to send to Kafka into bytes.  The deserialization process is the opposite.  It receives the bytes from Kafka and recreates the business objects."
msgstr "当你的应用程序将一条 _记录_ 写入Kafka主题或从Kafka主题消费一条 _记录_ 时，会发生序列化和反序列化的机制。序列化过程将你要发送给Kafka的业务对象转化为字节。反序列化过程则是相反的。它接收来自Kafka的字节并重新创建业务对象。"

#. type: Target for macro image
#: upstream/_posts/2022-08-30-kafka-serde.adoc:15
#, no-wrap
msgid "/assets/images/posts/kafka-serde/serde.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:18
#, fuzzy
msgid "This blog post explores different approaches for this serialization and deserialization and explains how you can implement a custom serializer and deserializer. It also highlights facilities provided by the Kafka connector from Quarkus."
msgstr "这篇博文探讨了这种序列化和反序列化的不同方法，并解释了你如何实现一个自定义的序列化器和反序列化器。它还强调了Quarkus的Kafka连接器所提供的设施。"

#. type: Title ==
#: upstream/_posts/2022-08-30-kafka-serde.adoc:19
#, fuzzy, no-wrap
msgid "Why do I need a custom serializer and deserializer?"
msgstr "为什么我需要一个自定义的序列化器和反序列化器？"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:23
#, fuzzy
msgid "https://javadoc.io/static/org.apache.kafka/kafka-clients/3.2.1/org/apache/kafka/common/serialization/package-summary.html[Kafka] provides a set of serializers and deserializers for the common types: `String`, `Double`, `Integer`, `Bytes`...  But that's rarely enough for business objects, even for objects are simple as:"
msgstr "link:https://javadoc.io/static/org.apache.kafka/kafka-clients/3.2.1/org/apache/kafka/common/serialization/package-summary.html[Kafka] 为常见的类型提供了一套序列化器和反序列化器。 `String` , `Double` , `Integer` , `Bytes` ......但这对于业务对象来说很少是足够的，甚至对于简单的对象也是如此。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:27
#: upstream/_posts/2022-08-30-kafka-serde.adoc:164
#, no-wrap
msgid "package me.escoffier.quarkus;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:29
#, no-wrap
msgid "public record Hero(String name, String picture) {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:31
#: upstream/_posts/2022-08-30-kafka-serde.adoc:190
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:35
#, fuzzy
msgid "Fortunately, Kafka lets us implement our own.  To achieve this, you need to implement the following interfaces:"
msgstr "幸运的是，Kafka允许我们实现自己的。为了实现这一点，你需要实现以下接口。"

#. type: Block title
#: upstream/_posts/2022-08-30-kafka-serde.adoc:36
#, fuzzy, no-wrap
msgid "The Serializer interface"
msgstr "串行器接口"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:40
#, no-wrap
msgid "public interface Serializer<T> extends Closeable {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:42
#: upstream/_posts/2022-08-30-kafka-serde.adoc:60
#, no-wrap
msgid "  default void configure(Map<String, ?> configs, boolean isKey) {  }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:44
#, no-wrap
msgid "  byte[] serialize(String topic, T data);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:48
#, no-wrap
msgid ""
"  default byte[] serialize(String topic, Headers headers, T data) {\n"
"    return serialize(topic, data);\n"
"  }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:52
#, no-wrap
msgid ""
"  @Override\n"
"  default void close() {   }\n"
"}\n"
msgstr ""

#. type: Block title
#: upstream/_posts/2022-08-30-kafka-serde.adoc:54
#, fuzzy, no-wrap
msgid "The Deserializer interface"
msgstr "反序列化器接口"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:58
#, no-wrap
msgid "public interface Deserializer<T> extends Closeable {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:62
#, no-wrap
msgid "  T deserialize(String topic, byte[] data);\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:66
#, no-wrap
msgid ""
"  default T deserialize(String topic, Headers headers, byte[] data) {\n"
"    return deserialize(topic, data);\n"
"  }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:69
#, no-wrap
msgid ""
"  @Override\n"
"  default void close() {  }\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:73
#, fuzzy
msgid "Once implemented, you need to configure your Kafka producer and consumer's key and value serializer and deserializer.  If you are using the Kafka connector from Quarkus, it will look like this:"
msgstr "一旦实现，你需要配置你的Kafka生产者和消费者的键和值序列化器和解序列化器。如果你使用的是Quarkus的Kafka连接器，它看起来会像这样。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:78
#, no-wrap
msgid ""
"mp.messaging.incoming.heroes.value.deserializer=me.escoffier.MyHeroDeserializer\n"
"mp.messaging.outgoing.heroes.value.serializer=me.escoffier.MyHeroSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:81
#, fuzzy
msgid "But, no worries, Quarkus has a few magic tricks for you."
msgstr "但是，不用担心，夸库斯为你准备了一些神奇的技巧。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:83
#, fuzzy
msgid "In the rest of this post, we will use the following application:"
msgstr "在这篇文章的其余部分，我们将使用以下应用程序。"

#. type: Target for macro image
#: upstream/_posts/2022-08-30-kafka-serde.adoc:84
#, no-wrap
msgid "/assets/images/posts/kafka-serde/system.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:88
#, fuzzy
msgid "The code can be found on https://github.com/cescoffier/quarkus-kafka-serde-demo.  We will develop three variants:"
msgstr "该代码可以在 https://github.com/cescoffier/quarkus-kafka-serde-demo 我们将开发三种变体。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:90
#, fuzzy
msgid "The first version uses JSON."
msgstr "第一个版本使用JSON。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:91
#, fuzzy
msgid "The second version uses Avro."
msgstr "第二个版本使用阿夫罗。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:92
#, fuzzy
msgid "The third version uses custom (and dumb) serializer and deserializer."
msgstr "第三个版本使用自定义的（也是愚蠢的）序列化器和解序列化器。"

#. type: Title ==
#: upstream/_posts/2022-08-30-kafka-serde.adoc:93
#, fuzzy, no-wrap
msgid "Using JSON"
msgstr "使用JSON"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:97
#, fuzzy
msgid "Using JSON with Kafka is very popular.  As most web applications use JSON to exchange messages, using it with Kafka sounds like a natural extension."
msgstr "在Kafka中使用JSON是非常流行的。由于大多数Web应用都使用JSON来交换消息，将其与Kafka一起使用听起来是一个自然的延伸。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:101
#, fuzzy
msgid "In our case, it means transforming the instances of https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/json-serde/json-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/Hero.java[Hero] to a JSON document and then using the String serializer.  For the deserialization process, we would do the reverse process.  To do that with Quarkus, you have *nothing* to do: Quarkus generates the custom JSON serializer and deserializer for you."
msgstr "在我们的例子中，这意味着将 link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/json-serde/json-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/Hero.java[Hero] 的实例转换为JSON文档，然后使用String序列化器。对于反序列化过程，我们会做相反的过程。要用Quarkus做这个，你 *什么都不用* 做。Quarkus为你生成了自定义的JSON序列化器和反序列化器。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:107
#, fuzzy
msgid "In the https://github.com/cescoffier/quarkus-kafka-serde-demo/tree/main/json-serde[json-serde directory], you can find a version of the application using JSON to serialize and deserialize the records.  It does not contain any custom code or configuration.  Quarkus automatically detects that you need to write and consume Heroes and generates the serializer and deserializer for you.  It also configures the channels for you.  Of course, you can override the configuration, but it's what you want most of the time."
msgstr "在 link:https://github.com/cescoffier/quarkus-kafka-serde-demo/tree/main/json-serde[json-serde目录] 中，你可以找到一个使用JSON来序列化和反序列化记录的应用程序版本。它不包含任何自定义代码或配置。Quarkus自动检测到你需要编写和消费Heroes，并为你生成了序列化器和反序列化器。它还为你配置了通道。当然，你可以覆盖配置，但这是你在大多数时候想要的。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:113
#, fuzzy
msgid "To run this application, open two terminals.  In the first one, navigate to `json-serde/json-serde-publisher`, and run `mvn quarkus:dev`.  In the second terminal, navigate to `json-serde/json-serde-consumer`, and run `mvn quarkus:dev`.  Then, open a browser to http://localhost:8080.  Every 5 seconds, a new picture of a hero is displayed."
msgstr "要运行这个应用程序，请打开两个终端。在第一个终端中，导航到 `json-serde/json-serde-publisher` ，并运行 `mvn quarkus:dev` 。在第二个终端中，导航到 `json-serde/json-serde-consumer` ，并运行 `mvn quarkus:dev` 。然后，打开一个浏览器到 http://localhost:8080 每隔5秒，就会显示一张新的英雄图片。"

#. type: Target for macro image
#: upstream/_posts/2022-08-30-kafka-serde.adoc:114
#, no-wrap
msgid "/assets/images/posts/kafka-serde/heroes-screenshot.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2022-08-30-kafka-serde.adoc:116
#, fuzzy, no-wrap
msgid "Using Avro"
msgstr "使用Avro"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:120
#, fuzzy
msgid "The second approach uses https://avro.apache.org/[Avro].  Avro has several advantages over (bare) JSON:"
msgstr "第二种方法使用 link:https://avro.apache.org/[Avro] 。与（裸）JSON相比，Avro有几个优点。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:122
#, fuzzy
msgid "It's a binary and compact protocol. The payloads will be a lot smaller than with JSON."
msgstr "这是一个二进制和紧凑的协议。有效载荷将比用JSON小得多。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:123
#, fuzzy
msgid "The serialization and deserialization processes are a lot faster (avoiding reflection)."
msgstr "序列化和反序列化过程要快得多（避免了反射）。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:124
#, fuzzy
msgid "The format of the message is defined using a schema stored on a schema registry which enables versioning and enforces the structure."
msgstr "消息的格式是使用存储在模式注册表上的模式来定义的，该模式可以进行版本管理并强制执行结构。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:129
#, fuzzy
msgid "The last point is essential.  To use Avro, you need a schema registry.  In this post, we are using https://www.apicur.io/registry/[Apicurio], but you can use the https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry] or https://github.com/aiven/karapace[Karapace].  Quarkus provides a dev service for Apicurio, so you have nothing to do (as soon as you can run containers on your machine)."
msgstr "最后一点是至关重要的。要使用Avro，你需要一个模式注册表。在这篇文章中，我们使用的是 link:https://www.apicur.io/registry/[Apicurio] ，但你可以使用 link:https://docs.confluent.io/platform/current/schema-registry/index.html[Confluent Schema Registry] 或 link:https://github.com/aiven/karapace[Karapace] 。Quarkus为Apicurio提供了一个开发服务，所以你没有什么可做的（只要你能在你的机器上运行容器）。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:132
#, fuzzy
msgid "To use Avro, we need a schema.  In https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-consumer/src/main/avro/hero.avsc[hero.avsc], you can find the schema representing our heroes:"
msgstr "为了使用Avro，我们需要一个模式。在 link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-consumer/src/main/avro/hero.avsc[hero.avsc] 中，你可以找到代表我们英雄的模式。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:150
#, no-wrap
msgid ""
"{\n"
"  \"namespace\": \"me.escoffier.quarkus.avro\",\n"
"  \"type\": \"record\",\n"
"  \"name\": \"Hero\",\n"
"  \"fields\": [\n"
"    {\n"
"      \"name\": \"name\",\n"
"      \"type\": \"string\"\n"
"    },\n"
"    {\n"
"      \"name\": \"picture\",\n"
"      \"type\": \"string\"\n"
"    }\n"
"  ]\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:154
#, fuzzy
msgid "Avro relies on code generation.  It processes the schema to generate Java classes with the defined fields and serialization and deserialization methods."
msgstr "Avro依赖于代码生成。它处理模式以生成具有定义的字段和序列化及反序列化方法的Java类。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:157
#, fuzzy
msgid "While in general, using code generation is an extra step, with Quarkus, it's built-in! Once you have a schema in `src/main/avro`, it generates the code for you, and you are ready to use the produced classes."
msgstr "虽然在一般情况下，使用代码生成是一个额外的步骤，但在Quarkus中，它是内置的。一旦你在 `src/main/avro` ，它就会为你生成代码，你就可以使用生成的类。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:160
#, fuzzy
msgid "In https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/AvroPublisherApp.java[AvroPublisherApp] and https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-consumer/src/main/java/me/escoffier/quarkus/AvroConsumerResource.java[AvroConsumerResource], we are using the `Hero` class generated from the schema.  As an example, the consumer application looks like this:"
msgstr "在 link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/AvroPublisherApp.java[AvroPublisherApp] 和 link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/avro-serde/avro-serde-consumer/src/main/java/me/escoffier/quarkus/AvroConsumerResource.java[AvroConsumerResource] 中，我们正在使用从模式中生成的 `Hero` 。作为一个例子，消费者应用程序看起来像这样。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:169
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import me.escoffier.quarkus.avro.Hero;   // Generated class\n"
"import org.eclipse.microprofile.reactive.messaging.Channel;\n"
"import org.jboss.resteasy.reactive.RestStreamElementType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:174
#, no-wrap
msgid ""
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:177
#, no-wrap
msgid ""
"@Path(\"/heroes\")\n"
"public class AvroConsumerResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:180
#, no-wrap
msgid ""
"    @Channel(\"heroes\")\n"
"    Multi<Hero> heroes;  // The hero class is generated from the schema.\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:187
#, no-wrap
msgid ""
"    @GET\n"
"    @Produces(MediaType.SERVER_SENT_EVENTS)\n"
"    @RestStreamElementType(MediaType.APPLICATION_JSON)\n"
"    public Multi<Hero> stream() {\n"
"        return heroes;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:195
#, fuzzy
msgid "Quarkus automatically finds the serializer and deserializer and configures the channels, so again: *no config*.  However, you still need to instruct Apicurio to register the schema.  In general, it's a manual operation, but for development, you can use the following property:"
msgstr "Quarkus会自动找到序列化器和反序列化器并配置通道，所以还是那句话： *不用配置* 。然而，你仍然需要指示Apicurio注册模式。一般来说，这是一个手动操作，但对于开发来说，你可以使用以下属性。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:199
#, no-wrap
msgid "kafka.apicurio.registry.auto-register=true\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:207
#, fuzzy
msgid "To run this application, open two terminals.  In the first one, navigate to `avro-serde/avro-serde-publisher`, and run `mvn quarkus:dev`.  In the second terminal, navigate to `avro-serde/avro-serde-consumer`, and run `mvn quarkus:dev`.  Then, open a browser to http://localhost:8080.  As for the JSON variant, every 5 seconds, a new picture of a hero is displayed.  This time the Kafka records are serialized using Avro"
msgstr "要运行这个应用程序，请打开两个终端。在第一个终端，导航到 `avro-serde/avro-serde-publisher` ，并运行 `mvn quarkus:dev` 。在第二个终端中，导航到 `avro-serde/avro-serde-consumer` ，并运行 `mvn quarkus:dev` 。然后，打开一个浏览器到 http://localhost:8080 至于JSON的变体，每5秒就会显示一张新的英雄图片。这一次，Kafka记录被序列化，使用Avro"

#. type: Title ==
#: upstream/_posts/2022-08-30-kafka-serde.adoc:208
#, fuzzy, no-wrap
msgid "Writing a custom serializer and deserializer"
msgstr "编写一个自定义的序列化器和反序列化器"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:212
#, fuzzy
msgid "Of course, you can still write your custom serializer and deserializer.  As mentioned above, you need to implement the `Serializer` and `Deserializer` interfaces."
msgstr "当然，你仍然可以编写你的自定义序列化器和反序列化器。如上所述，你需要实现 `Serializer` 和 `Deserializer` 接口。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:214
#, fuzzy
msgid "For example, the https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/custom-serde/custom-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/HeroSerializer.java[HeroSerializer class] contains a straightforward (and inefficient) approach to serializing our heroes:"
msgstr "例如， link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/custom-serde/custom-serde-publisher/src/main/java/me/escoffier/quarkus/json/publisher/HeroSerializer.java[HeroSerializer类] 包含一个直接的（低效的）方法来序列化我们的英雄。"

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:218
#, no-wrap
msgid "package me.escoffier.quarkus.json.publisher;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:220
#, no-wrap
msgid "import org.apache.kafka.common.serialization.Serializer;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:222
#, no-wrap
msgid "import java.nio.charset.StandardCharsets;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:224
#, no-wrap
msgid "public class HeroSerializer implements Serializer<Hero> {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2022-08-30-kafka-serde.adoc:231
#, no-wrap
msgid ""
"    @Override\n"
"    public byte[] serialize(String topic, Hero data) {\n"
"        return (data.name() + \",\" + data.picture())\n"
"                .getBytes(StandardCharsets.UTF_8);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:234
#, fuzzy
msgid "The https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/custom-serde/custom-serde-consumer/src/main/java/me/escoffier/quarkus/HeroDeserializer.java[HeroDeserializer class] contains the deserialization counterpart."
msgstr "link:https://github.com/cescoffier/quarkus-kafka-serde-demo/blob/main/custom-serde/custom-serde-consumer/src/main/java/me/escoffier/quarkus/HeroDeserializer.java[HeroDeserializer类] 包含了反序列化的对应部分。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:237
#, fuzzy
msgid "As before, Quarkus discovers these implementations and configures the channels for you.  So you do not have to configure anything."
msgstr "和以前一样，Quarkus发现这些实现并为你配置通道。所以你不需要配置任何东西。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:240
#, fuzzy
msgid "Custom serializers and deserializers can receive configuration attributes.  They receive the producer/consumer configuration in the `configure` method."
msgstr "自定义序列化器和反序列化器可以接收配置属性。他们在 `configure` 方法中接收生产者/消费者的配置。"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:242
#, fuzzy
msgid "Custom serializers and deserializers cannot be CDI beans. Kafka instantiates them directly using reflection."
msgstr "自定义序列化器和反序列化器不能是CDI beans。Kafka使用反射直接将它们实例化。"

#. type: Title ==
#: upstream/_posts/2022-08-30-kafka-serde.adoc:243
#, fuzzy, no-wrap
msgid "Conclusion"
msgstr "总结"

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:246
msgid "This post explores different possibilities to serialize and deserialize your messages with Kafka and how Quarkus reduces the amount of boilerplate and configuration you need to use."
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:248
msgid "So, what should you use?"
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:250
msgid "JSON is massively used, but the lack of structure verification, by default, can quickly be a problem if the format evolves rapidly."
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:251
msgid "Avro provides better performances and handles validation and evolutions. But it requires a schema registry. If your system exchanges lots of messages with evolving structures, Avro should be preferred. Also, Avro produces smaller payloads."
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:252
msgid "If you have stringent requirements not covered by the JSON and Avro approaches, you can develop a custom serializer and deserializer."
msgstr ""

#. type: Plain text
#: upstream/_posts/2022-08-30-kafka-serde.adoc:254
msgid "Note that JSON can be combined with JSON-Schema (with the schema stored on a schema registry). Protobuf is also a possible alternative if you prefer a binary format."
msgstr ""
