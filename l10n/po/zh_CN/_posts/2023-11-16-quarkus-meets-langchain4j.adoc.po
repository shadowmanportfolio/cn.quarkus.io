# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2023-11-15 18:20+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "cescoffier"
msgstr ""

#. type: YAML Front Matter: date
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "2023-11-15"
msgstr ""

#. type: YAML Front Matter: layout
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "post"
msgstr ""

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "Learn about the new quarkus-langchain4j extension to integrate LLMs in Quarkus applications."
msgstr ""

#. type: YAML Front Matter: tags
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "AI langchain"
msgstr ""

#. type: YAML Front Matter: title
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:1
#, no-wrap
msgid "When Quarkus meets LangChain4j"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:12
msgid "Large language models (LLMs) are reshaping the world of software, altering the way we interact with users and develop business logic."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:14
msgid "Popularized by https://openai.com/[OpenAI]'s https://chat.openai.com/[ChatGPT], LLMs are now available in many flavors and sizes. The https://huggingface.co/models[Hugging-Face] platform references hundreds of them, and major tech companies like Facebook, Google, Microsoft, Amazon and IBM are also providing their own models."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:16
msgid "LLMs are not a new concept. They have been around for a while, but they were not as powerful or as accessible the became when OpenAI made ChatGPT API's publically available. Since then the Quarkus team have been thinking about what it would mean to integrate LLMs in the Quarkus ecosystem. The talk https://www.youtube.com/watch?app=desktop&v=BD1MSLbs9KE[Java Meets AI] from Lize Raes at Devoxx 2023 has been a great source of inspiration."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:18
msgid "Since, the Quarkus team, in collaboration with Dmytro Liubarskyi and the LangChain4j team, has been working on an extension to integrate LLMs in Quarkus applications. This extension is based on the https://github.com/langchain4j[LangChain4j library], which provides a common API to interact with LLMs. The LangChain4j project is a Java re-implementation of the famous https://www.langchain.com/[langchain] library."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:20
msgid "In this blog post, we will see how to use the just released https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html[quarkus-langchain4j] 0.1 extension to integrate LLMs in Quarkus applications. This extension is an exploration to understand how LLMs can be used in Quarkus applications."
msgstr ""

#. type: Title ==
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:21
#, no-wrap
msgid "Overview"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:24
msgid "First, let's have a look at the big picture. When integrating an LLM into a Quarkus application, you need to describe what you want the AI to do. Unlike traditional code, you are going to explain the behavior of the AI using natural language. Of course, there are a few techniques to tame the AI, but we will explore that later."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:26
msgid "Strictly relying on the LLM's knowledge might not be enough. Thus, the Quarkus LangChain4j extension provides two mechanisms to extend AI knowledge:"
msgstr ""

#. type: Bullet: '1) '
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:28
msgid "Tools - a tool lets the LLM execute actions in your application. For instance, you can use a tool to send an email, call a REST endpoint, or execute a database query. The LLM decides when to use the tool, the method parameters, and what to do with the result."
msgstr ""

#. type: Bullet: '2) '
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:29
msgid "Document stores - LLMs are not good at remembering things. In addition, their context has a size limit. Thus, the extension provides a way to store and retrieve information from document stores. Before calling the LLM, the extension can ask for relevant documents in a document store and attach them to the context. The LLM can then use this data to make a decision. For instance, you can load spreadsheet data, reports, or data from a database."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:31
msgid "The following diagram illustrates the interactions between the LLM, the tools, and the document stores:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:32
#, no-wrap
msgid "Quarkus LLM integration - the big picture"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:32
#, no-wrap
msgid "llms-big-picture.png"
msgstr ""

#. type: Title ==
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:35
#, no-wrap
msgid "Show me some code!"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:38
msgid "Alright, enough \"bla bla\", let's see some code! We are going to use Open AI GPT-3.5 (be careful that it's not the state-of-the-art model, but it's good enough for this demo), give it some product reviews, and ask the LLM to classify them between positive and negative reviews. The full code is available in the https://github.com/quarkiverse/quarkus-langchain4j/tree/main/samples/review-triage[quarkus-langchain4j repository]."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:40
msgid "First, we need the `quarkus-langchain4j-openai` extension:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:48
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkiverse.langchain4j</groupId>\n"
"    <artifactId>quarkus-langchain4j-openai</artifactId>\n"
"    <version>0.1.0</version> <!-- Update to use the latest version -->\n"
"</dependency>\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:51
msgid "Once we have the extension, it's time to tell the LLM what we want to do. The Quarkus LangChain4J extension provides a declarative way to describe LLM interactions. The idea is the same as the Quarkus REST client. We model the interaction using an interface annotated with `@RegisterAiService`:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:58
#, no-wrap
msgid ""
"@RegisterAiService\n"
"public interface TriageService {\n"
"    // methods.\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:61
msgid "The rest of the application would be able to use the LLM by injecting the `TriageService` interface and calling the methods."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:63
msgid "Speaking about methods, that's where the magic happens. You will describe what you want the LLM to do using natural language. First, you start with `@SystemMessage` to define the role and scope. Then, you can use `@UserMessage` to describe the task."
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:78
#, no-wrap
msgid ""
"@RegisterAiService\n"
"public interface TriageService {\n"
"    @SystemMessage(\"\"\"\n"
"        You are working for a bank, processing reviews about \n"
"        financial products. Triage reviews into positive and \n"
"        negative ones, responding with a JSON document.\n"
"        \"\"\"\n"
"    )\n"
"    @UserMessage(\"\"\"\n"
"        Your task is to process the review delimited by ---.\n"
"        Apply sentiment analysis to the review to determine \n"
"        if it is positive or negative, considering various languages.\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:83
#, no-wrap
msgid ""
"        For example:\n"
"        - `I love your bank, you are the best!` is a 'POSITIVE' review\n"
"        - `J'adore votre banque` is a 'POSITIVE' review\n"
"        - `I hate your bank, you are the worst!` is a 'NEGATIVE' review\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:90
#, no-wrap
msgid ""
"        Respond with a JSON document containing:\n"
"        - the 'evaluation' key set to 'POSITIVE' if the review is \n"
"        positive, 'NEGATIVE' otherwise\n"
"        - the 'message' key set to a message thanking or apologizing \n"
"        to the customer. These messages must be polite and match the     \n"
"        review's language.\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:97
#, no-wrap
msgid ""
"        ---\n"
"        {review}\n"
"        ---\n"
"    \"\"\")\n"
"    TriagedReview triage(String review);\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:100
msgid "Voilà! That's all you need to do to describe the interaction with the LLM. The instructions follow a set of principles to shape the LLM response. Learn more about these techniques in https://docs.quarkiverse.io/quarkus-langchain4j/dev/prompt-engineering.html[the dedicated prompt engineering page]."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:102
msgid "Now, to call the LLM from the application code, just inject the `TriageService` and call the `triage` method:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:107
#, no-wrap
msgid ""
"@Path(\"/review\")\n"
"public class ReviewResource {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:110
#, no-wrap
msgid ""
"    @Inject\n"
"    TriageService triage;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:114
#, no-wrap
msgid ""
"    record Review(String review) {\n"
"      // User text\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:119
#, no-wrap
msgid ""
"    @POST\n"
"    public TriagedReview triage(Review review) {\n"
"        return triage.triage(review.review());\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:121
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:150
#, no-wrap
msgid "}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:124
msgid "That's it! The LLM is now integrated into the application. The `TriageService` interface is used as an ambassador to call the LLM. This declarative approach has many advantages:"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:126
msgid "Testability - you can easily mock the LLM by providing a fake implementation of the interface."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:127
msgid "Observability - you can use the Quarkus metrics annotation to monitor the LLM methods."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:128
msgid "Resilience - you can use the Quarkus fault-tolerance annotations to handle failures, timeouts, and other transient issues."
msgstr ""

#. type: Title ==
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:129
#, no-wrap
msgid "Tools and Document loader"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:132
msgid "The previous example is a bit simplistic. In the real world, you will need to extend the LLM knowledge with tools and document stores. The `@RegisterAiService` annotation lets you define the tools and document stores to use."
msgstr ""

#. type: Title ===
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:133
#, no-wrap
msgid "Tools"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:136
msgid "Tools are methods that the LLM can invoke."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:138
msgid "To declare a tool, just use the `@Tool` annotation on a _bean_ method:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:143
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class CustomerRepository implements PanacheRepository<Customer> {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:148
#, no-wrap
msgid ""
"    @Tool(\"get the customer name for the given customerId\")\n"
"    public String getCustomerName(long id) {\n"
"        return find(\"id\", id).firstResult().name;\n"
"    }\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:153
msgid "In this example, we are using the Panache repository pattern to access the database. We have a specific method annotated with `@Tool` to retrieve the customer name. When the LLM needs to get the customer name, it instructs Quarkus to call this method and receives the result."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:155
msgid "Obviously, it's not a good idea to expose every operation to the LLM. So, in addition to `@Tool`, you need to list the set of tools you allow the LLM to invoke in the `@RegisterAiService` annotation:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:165
#, no-wrap
msgid ""
"@RegisterAiService(\n"
"    tools = { TransactionRepository.class, CustomerRepository.class },\n"
"    chatMemoryProviderSupplier = RegisterAiService.BeanChatMemoryProviderSupplier.class\n"
")\n"
"public interface FraudDetectionAi {\n"
"   // ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:168
msgid "The `chatMemoryProviderSupplier` configuration may raise questions. When using tools, a sequence of messages unfolds behind the scenes. It becomes necessary to configure the AI service's memory to adeptly track these interactions. The `chatMemoryProviderSupplier` allows configuring how the memory is handled. The value `BeanChatMemoryProviderSupplier.class` instructs Quarkus to look for a `ChatMemoryProvider` bean, like the following:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:173
#, no-wrap
msgid ""
"@RequestScoped\n"
"public class ChatMemoryBean implements ChatMemoryProvider {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:175
#, no-wrap
msgid "    Map<Object, ChatMemory> memories = new ConcurrentHashMap<>();\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:185
#, no-wrap
msgid ""
"    @Override\n"
"    public ChatMemory get(Object memoryId) {\n"
"        return memories.computeIfAbsent(memoryId, \n"
"            id -> MessageWindowChatMemory.builder()\n"
"                    .maxMessages(20)\n"
"                    .id(memoryId)\n"
"                    .build()\n"
"            );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:191
#, no-wrap
msgid ""
"    @PreDestroy\n"
"    public void close() {\n"
"        memories.clear();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:194
msgid "At the moment, only the OpenAI models support tools."
msgstr ""

#. type: Title ===
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:195
#, no-wrap
msgid "Document stores"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:198
msgid "Document stores are a way to extend the LLM knowledge with your own data. This approach - called Retrieval Augmented Generation (_RAG_) - requires two processes:"
msgstr ""

#. type: Labeled list
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:199
#, no-wrap
msgid "The ingestion process"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:200
msgid "you ingest documents into a document store. The documents are not stored as-is, but an embedding is computed. This embedding is a vector representation of the document."
msgstr ""

#. type: Labeled list
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:201
#, no-wrap
msgid "The RAG process"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:202
msgid "in the Quarkus application, you need to declare the document store and the embedding to use. Thus, before calling the LLM, it retrieves the relevant documents from the store (that's where the vector representation is useful) and attaches them to the LLM context (which essentially means adding the retrieved information from the document to the user message)."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:204
msgid "The Quarkus LangChain4j extension provides facilities for both processes."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:206
msgid "The following code shows how to ingest a document into a Redis document store:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:211
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class IngestorExample {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:218
#, no-wrap
msgid ""
"    /**\n"
"     * The embedding store (the database).\n"
"     * The bean is provided by the quarkus-langchain4j-redis extension.\n"
"     */\n"
"    @Inject\n"
"    RedisEmbeddingStore store;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:225
#, no-wrap
msgid ""
"    /**\n"
"     * The embedding model (how the vector of a document is computed).\n"
"     * The bean is provided by the LLM (like openai) extension.\n"
"     */\n"
"    @Inject\n"
"    EmbeddingModel embeddingModel;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:235
#, no-wrap
msgid ""
"    public void ingest(List<Document> documents) {\n"
"        var ingestor = EmbeddingStoreIngestor.builder()\n"
"                .embeddingStore(store)\n"
"                .embeddingModel(embeddingModel)\n"
"                .documentSplitter(recursive(500, 0))\n"
"                .build();  \n"
"        ingestor.ingest(documents);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:238
msgid "Then, generally, in another application, you can use the populated document store to extend the LLM knowledge. First, create a bean implementing the `Retriever<TextSegment>` interface:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:243
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class RetrieverExample implements Retriever<TextSegment> {\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:245
#, no-wrap
msgid "    private final EmbeddingStoreRetriever retriever;\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:249
#, no-wrap
msgid ""
"    RetrieverExample(RedisEmbeddingStore store, EmbeddingModel model) {\n"
"        retriever = EmbeddingStoreRetriever.from(store, model, 20);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:255
#, no-wrap
msgid ""
"    @Override\n"
"    public List<TextSegment> findRelevant(String s) {\n"
"        return retriever.findRelevant(s);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:258
msgid "Then, add the document store and the retriever to the `@RegisterAiService` annotation:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:267
#, no-wrap
msgid ""
"@RegisterAiService(\n"
"    retrieverSupplier = RegisterAiService.BeanRetrieverSupplier.class\n"
")\n"
"public interface MyAiService {\n"
"// ...\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:270
msgid "`RegisterAiService.BeanRetrieverSupplier.class` is a special value looking for the `Retriever` bean in the Quarkus application."
msgstr ""

#. type: Title ==
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:271
#, no-wrap
msgid "Final notes"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:274
msgid "This post presented the Quarkus LangChain4j extension. This is the first version of the extension, and we continue exploring and experimenting with approaches to integrate LLMs into Quarkus applications. We are looking for feedback and ideas to improve these integrations. We are working on removing some rough angles, and exploring other ways to integrate LLMs and to bring developer joy when integrating with LLMs."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:276
msgid "This extension would not have been possible without the fantastic work from Dmytro Liubarskyi on the LangChain4j library. Our collaboration has allowed us to provide a Quarkus-friendly approach to integrate the library (including native compilation support) and shape a new way to integrate LLMs in Quarkus applications. The current design was tailored to enable Quarkus applications to use LLM easily. You can basically hook up any of your _beans_ as tools or ingest data into a store. In addition, any of your bean can now interact with an LLM."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-11-16-quarkus-meets-langchain4j.adoc:277
msgid "We are looking forward to continuing this collaboration and to see what you will build with this extension."
msgstr ""
